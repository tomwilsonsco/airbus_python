{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oneatlas import OneAtlasClient  # custom class in this repo\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import zipfile\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process overview\n",
    "- Convert input aoi layer into geojson polygons\n",
    "- For each aoi polygon feature:\n",
    "  - Search API for available images\n",
    "  - Plot the quicklook for each image found for that feature\n",
    "  - Place an order for the chosen image clipped to the feature\n",
    "  - Download the order once completed\n",
    "  - Extract the order tif image from zip into one directory and delete zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read local config.json to get api key and directory for outputs\n",
    "with open(\"config.json\", \"r\") as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "api_key = config[\"api_key\"]\n",
    "\n",
    "client = OneAtlasClient(api_key=api_key)\n",
    "\n",
    "output_folder = Path(config[\"output_dir\"])\n",
    "input_file_gdb = Path(config[\"input_gdb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert polygon gdf to bounding box list\n",
    "sites_gdf = gpd.read_file(input_file_gdb, layer=\"Registered_Sites_Merged_v2\")\n",
    "\n",
    "LAYER_NAME = \"Registered_Sites\"  # prefix name for the clipped image downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with 'POINT EMPTY' geometry\n",
    "sites_gdf = sites_gdf[~sites_gdf.geometry.is_empty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to convert points -> buffer -> bounding box\n",
    "def points_to_buffer_box(gdf, buffer_distance=500):\n",
    "    \"\"\"Buffer points by distance and convert to bounding boxes\"\"\"\n",
    "\n",
    "    # Check if all geometries are Points\n",
    "\n",
    "    if not all(gdf.geometry.geom_type == \"Point\"):\n",
    "\n",
    "        print(\"All geometries in the GeoDataFrame must be Points. Exiting.\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    # Reproject to EPSG 27700\n",
    "\n",
    "    gdf = gdf.to_crs(epsg=27700)\n",
    "\n",
    "    # Buffer the geometries\n",
    "\n",
    "    gdf[\"geometry\"] = gdf.geometry.buffer(buffer_distance)\n",
    "\n",
    "    # Convert buffers to bounding boxes\n",
    "\n",
    "    gdf[\"geometry\"] = gdf.geometry.apply(lambda geom: box(*geom.bounds))\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert points geometry to bounding box around 500m buffer\n",
    "sites_box_gdf = points_to_buffer_box(sites_gdf, buffer_distance=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aoi_gdf_to_search_geojson(gdf, uid_column=None):\n",
    "    \"\"\"Convert geodataframe to geojson ensuring unique ids per feature\"\"\"\n",
    "\n",
    "    if uid_column is None:\n",
    "\n",
    "        uid_column = \"id\"\n",
    "\n",
    "        gdf[uid_column] = gdf.index\n",
    "\n",
    "    else:\n",
    "\n",
    "        if not gdf[uid_column].is_unique:\n",
    "\n",
    "            raise ValueError(\n",
    "                f\"Values in '{uid_column}' are not unique. Consider using default uid_column=None to add uids.\"\n",
    "            )\n",
    "\n",
    "    print(\n",
    "        f\"uid_column '{uid_column}' values {', '.join(str(i) for i in gdf[uid_column].tolist())}\"\n",
    "    )\n",
    "\n",
    "    json_str = gdf[[uid_column, \"geometry\"]].to_crs(epsg=4326).to_json(drop_id=True)\n",
    "\n",
    "    return json.loads(json_str), gdf[uid_column].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert gdf to geojson and get the id value list to know ids to search for\n",
    "search_geojson, id_vals = aoi_gdf_to_search_geojson(\n",
    "    sites_box_gdf, uid_column=\"image_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_by_id(geojson, id_vals, search_id, uid_column=\"id\"):\n",
    "    \"\"\"Filter geojson features to just one specified id\"\"\"\n",
    "\n",
    "    if search_id not in id_vals:\n",
    "\n",
    "        raise ValueError(f\"id {search_id} not in list of id values\")\n",
    "\n",
    "    for feature in geojson[\"features\"]:\n",
    "\n",
    "        if feature[\"properties\"][uid_column] == search_id:\n",
    "            return feature\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the search id. Must be in the id_vals list created above.\n",
    "SEARCH_ID = 16\n",
    "# extract the geojson feature for that id\n",
    "search_feature = get_feature_by_id(\n",
    "    search_geojson, id_vals, SEARCH_ID, uid_column=\"image_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search options are described [here](https://www.geoapi-airbusds.com/guides/oneatlas-data/g-search/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create search json - geometry is the search feature geometry\n",
    "img_search_json = {\n",
    "    \"cloudCover\": \"[0,30]\",\n",
    "    \"incidenceAngle\": \"[0,40]\",\n",
    "    \"processingLevel\": \"SENSOR\",\n",
    "    \"relation\": \"contains\",\n",
    "    \"geometry\": search_feature[\"geometry\"],\n",
    "    \"constellation\": \"PHR\",\n",
    "}\n",
    "\n",
    "# make the request\n",
    "results = client.search(img_search_json)\n",
    "\n",
    "# extract relevant values from the results and store in client instance\n",
    "\n",
    "\n",
    "client.extract_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell repeatedly to show each search result image quicklook in turn\n",
    "client.show_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the order options [here](https://www.geoapi-airbusds.com/guides/oneatlas-data/g-order-product/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the order specification and initially just quote the price\n",
    "order_body = {\n",
    "    \"kind\": \"order.data.product\",\n",
    "    \"products\": [\n",
    "        {\n",
    "            \"productType\": \"pansharpened\",  # pansharpened # multiSpectral\n",
    "            \"radiometricProcessing\": \"DISPLAY\",  # REFLECTANCE # DISPLAY #\n",
    "            \"imageFormat\": \"image/geotiff\",\n",
    "            \"crsCode\": \"urn:ogc:def:crs:EPSG::32630\",  # UTM zone for Scotland\n",
    "            \"id\": client.current_image,  # current client.show_result() image\n",
    "            \"aoi\": search_feature[\"geometry\"],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "client.get_price(order_body)[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a ref to identify the order\n",
    "order_ref = f\"sg_{LAYER_NAME}_{SEARCH_ID}\"\n",
    "\n",
    "order_body[\"customerRef\"] = order_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below to place the order above (WARNING: account will be charged)\n",
    "client.create_order(order_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See order status - need to keep checking by running this until shows \"delivered\"\n",
    "status = \"\"\n",
    "while status != \"delivered\":\n",
    "\n",
    "    orders = client.list_orders(customerRef=order_ref)\n",
    "\n",
    "    order = orders[\"items\"][0]\n",
    "\n",
    "    status = order[\"status\"]\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The config.json in the repo specifies the output_folder (I'm using _PS if pan-sharpened)\n",
    "output_file = output_folder / f\"{LAYER_NAME}_PS_{SEARCH_ID}.zip\"\n",
    "\n",
    "# Download the order to specified zip file\n",
    "client.download_order_to_file(order, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_zip_file(zip_file_path, target_directory, delete_zip=True):\n",
    "    \"\"\"Extract largest tif image from zip and store in local directory\"\"\"\n",
    "\n",
    "    zip_file_path = Path(zip_file_path)\n",
    "\n",
    "    target_directory = Path(target_directory)\n",
    "\n",
    "\n",
    "    # Extract the ZIP file\n",
    "\n",
    "    with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "\n",
    "        temp_extract_dir = zip_file_path.parent / \"temp_extracted\"\n",
    "\n",
    "        zip_ref.extractall(temp_extract_dir)\n",
    "\n",
    "\n",
    "    # Find the largest .tif file\n",
    "\n",
    "    largest_tif_file = None\n",
    "\n",
    "    largest_size = 0\n",
    "\n",
    "    for file in temp_extract_dir.rglob(\"*.TIF\"):\n",
    "\n",
    "        if file.stat().st_size > largest_size:\n",
    "\n",
    "            largest_tif_file = file\n",
    "\n",
    "            largest_size = file.stat().st_size\n",
    "\n",
    "\n",
    "    if largest_tif_file is not None:\n",
    "\n",
    "        # Copy it to the target directory with _<number> appended to the file name\n",
    "\n",
    "        number_suffix = zip_file_path.stem.split(\"_\")[-1]\n",
    "\n",
    "        new_file_name = (\n",
    "\n",
    "            largest_tif_file.stem + f\"_{number_suffix}\" + largest_tif_file.suffix\n",
    "        )\n",
    "\n",
    "        target_file_path = target_directory / new_file_name\n",
    "\n",
    "        shutil.copy(largest_tif_file, target_file_path)\n",
    "\n",
    "\n",
    "        # Delete the extracted ZIP file and temporary directory\n",
    "\n",
    "        shutil.rmtree(temp_extract_dir)\n",
    "\n",
    "        if delete_zip:\n",
    "\n",
    "            zip_file_path.unlink()\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"No .tif files found in the ZIP archive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_zip_file(output_file, output_folder / \"extracted_images\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0be6a230cf1e51d09a2a433a1ab7b0fc195a7ed433ae26bb34d0f4728802d05"
  },
  "kernelspec": {
   "display_name": "Python 3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
