{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oneatlas import OneAtlasClient  # custom class in this repo\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import zipfile\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process overview\n",
    "- Convert input aoi layer into geojson polygons\n",
    "- For each aoi polygon feature:\n",
    "  - Search API for available images\n",
    "  - Plot the quicklook for each image found for that feature\n",
    "  - Place an order for the chosen image clipped to the feature\n",
    "  - Download the order once completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read local config.json to get api key and directory for outputs\n",
    "with open(\"config.json\", \"r\") as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "api_key = config[\"api_key\"]\n",
    "\n",
    "client = OneAtlasClient(api_key=api_key)\n",
    "\n",
    "output_folder = Path(config[\"output_dir\"])\n",
    "input_file_gdb = Path(config[\"input_gdb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert polygon gdf to bounding box list\n",
    "sites_gdf = gpd.read_file(input_file_gdb, layer=\"Registered_Sites_Merged_v2\")\n",
    "\n",
    "LAYER_NAME = \"Registered_Sites\"  # prefix name for the clipped image downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with 'POINT EMPTY' geometry\n",
    "sites_gdf = sites_gdf[~sites_gdf.geometry.is_empty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to convert points -> buffer -> bounding box\n",
    "def points_to_buffer_box(gdf, buffer_distance=500):\n",
    "    \"\"\"Buffer points by distance and convert to bounding boxes\"\"\"\n",
    "\n",
    "    # Check if all geometries are Points\n",
    "\n",
    "    if not all(gdf.geometry.geom_type == \"Point\"):\n",
    "\n",
    "        print(\"All geometries in the GeoDataFrame must be Points. Exiting.\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    # Reproject to EPSG 27700\n",
    "\n",
    "    gdf = gdf.to_crs(epsg=27700)\n",
    "\n",
    "    # Buffer the geometries\n",
    "\n",
    "    gdf[\"geometry\"] = gdf.geometry.buffer(buffer_distance)\n",
    "\n",
    "    # Convert buffers to bounding boxes\n",
    "\n",
    "    gdf[\"geometry\"] = gdf.geometry.apply(lambda geom: box(*geom.bounds))\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert points geometry to bounding box around 500m buffer\n",
    "sites_box_gdf = points_to_buffer_box(sites_gdf, buffer_distance=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aoi_gdf_to_search_geojson(gdf, uid_column=None):\n",
    "    \"\"\"Convert geodataframe to geojson ensuring unique ids per feature\"\"\"\n",
    "\n",
    "    if uid_column is None:\n",
    "\n",
    "        uid_column = \"id\"\n",
    "\n",
    "        gdf[uid_column] = gdf.index\n",
    "\n",
    "    else:\n",
    "\n",
    "        if not gdf[uid_column].is_unique:\n",
    "\n",
    "            raise ValueError(\n",
    "                f\"Values in '{uid_column}' are not unique. Consider using default uid_column=None to add uids.\"\n",
    "            )\n",
    "\n",
    "    print(\n",
    "        f\"uid_column '{uid_column}' values {', '.join(str(i) for i in gdf[uid_column].tolist())}\"\n",
    "    )\n",
    "\n",
    "    json_str = gdf[[uid_column, \"geometry\"]].to_crs(epsg=4326).to_json(drop_id=True)\n",
    "\n",
    "    return json.loads(json_str), gdf[uid_column].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert gdf to geojson and get the id value list to know ids to search for\n",
    "search_geojson, id_vals = aoi_gdf_to_search_geojson(\n",
    "    sites_box_gdf, uid_column=\"image_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_by_id(geojson, id_vals, search_id, uid_column=\"id\"):\n",
    "    \"\"\"Filter geojson features to just one specified id\"\"\"\n",
    "\n",
    "    if search_id not in id_vals:\n",
    "\n",
    "        raise ValueError(f\"id {search_id} not in list of id values\")\n",
    "\n",
    "    for feature in geojson[\"features\"]:\n",
    "\n",
    "        if feature[\"properties\"][uid_column] == search_id:\n",
    "            return feature\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the search id. Must be in the id_vals list created above.\n",
    "SEARCH_ID = 4\n",
    "# extract the geojson feature for that id\n",
    "search_feature = get_feature_by_id(\n",
    "    search_geojson, id_vals, SEARCH_ID, uid_column=\"image_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search options are described [here](https://www.geoapi-airbusds.com/guides/oneatlas-data/g-search/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create search json - geometry is the search feature geometry\n",
    "img_search_json = {\n",
    "    \"cloudCover\": \"[0,30]\",\n",
    "    \"incidenceAngle\": \"[0,40]\",\n",
    "    \"processingLevel\": \"SENSOR\",\n",
    "    \"relation\": \"contains\",\n",
    "    \"geometry\": search_feature[\"geometry\"],\n",
    "    \"constellation\": \"PHR\",\n",
    "}\n",
    "\n",
    "# make the request\n",
    "results = client.search(img_search_json)\n",
    "\n",
    "# extract relevant values from the results and store in client instance\n",
    "\n",
    "\n",
    "client.extract_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell repeatedly to show each search result image quicklook in turn\n",
    "client.show_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the order options [here](https://www.geoapi-airbusds.com/guides/oneatlas-data/g-order-product/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the order specification and initially just quote the price\n",
    "order_body = {\n",
    "    \"kind\": \"order.data.product\",\n",
    "    \"products\": [\n",
    "        {\n",
    "            \"productType\": \"pansharpened\",  # pansharpened # multiSpectral\n",
    "            \"radiometricProcessing\": \"DISPLAY\",  # REFLECTANCE # DISPLAY #\n",
    "            \"imageFormat\": \"image/geotiff\",\n",
    "            \"crsCode\": \"urn:ogc:def:crs:EPSG::4326\",\n",
    "            \"id\": client.current_image,  # current client.show_result() image\n",
    "            \"aoi\": search_feature[\"geometry\"],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "client.get_price(order_body)[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a ref to identify the order\n",
    "order_ref = f\"sg_{LAYER_NAME}_{SEARCH_ID}\"\n",
    "\n",
    "order_body[\"customerRef\"] = order_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below to place the order above (WARNING: account will be charged)\n",
    "client.create_order(order_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See order status - need to keep checking by running this until shows \"delivered\"\n",
    "status = \"\"\n",
    "while status != \"delivered\":\n",
    "\n",
    "    orders = client.list_orders(customerRef=order_ref)\n",
    "\n",
    "\n",
    "    order = orders[\"items\"][0]\n",
    "\n",
    "\n",
    "    status = order[\"status\"]\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The config.json in the repo specifies the output_folder (I'm using _PS if pan-sharpened)\n",
    "output_file = output_folder / f\"{LAYER_NAME}_PS_{SEARCH_ID}.zip\"\n",
    "\n",
    "# Download the order to specified zip file\n",
    "client.download_order_to_file(order, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_zip_file(zip_file_path, target_directory, delete_zip=True):\n",
    "    zip_file_path = Path(zip_file_path)\n",
    "    target_directory = Path(target_directory)\n",
    "\n",
    "    # Extract the ZIP file\n",
    "    with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "        temp_extract_dir = zip_file_path.parent / \"temp_extracted\"\n",
    "        zip_ref.extractall(temp_extract_dir)\n",
    "\n",
    "    # Find the largest .tif file\n",
    "    largest_tif_file = None\n",
    "    largest_size = 0\n",
    "    for file in temp_extract_dir.rglob(\"*.TIF\"):\n",
    "        if file.stat().st_size > largest_size:\n",
    "            largest_tif_file = file\n",
    "            largest_size = file.stat().st_size\n",
    "\n",
    "    if largest_tif_file is not None:\n",
    "        # Copy it to the target directory with _<number> appended to the file name\n",
    "        number_suffix = zip_file_path.stem.split(\"_\")[-1]\n",
    "        new_file_name = (\n",
    "            largest_tif_file.stem + f\"_{number_suffix}\" + largest_tif_file.suffix\n",
    "        )\n",
    "        target_file_path = target_directory / new_file_name\n",
    "        shutil.copy(largest_tif_file, target_file_path)\n",
    "\n",
    "        # Delete the extracted ZIP file and temporary directory\n",
    "        shutil.rmtree(temp_extract_dir)\n",
    "        if delete_zip:\n",
    "            zip_file_path.unlink()\n",
    "    else:\n",
    "        print(\"No .tif files found in the ZIP archive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_zip_file(output_file, output_folder / \"extracted_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import A4\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def add_images_to_pdf(images_folder, pdf_path, gdf):\n",
    "    c = canvas.Canvas(str(pdf_path), pagesize=A4)\n",
    "    page_width, page_height = A4\n",
    "\n",
    "    images = list(Path(images_folder).glob(\"*.tif\"))\n",
    "    images.sort(key=lambda img: int(img.stem.split(\"_\")[-1]))\n",
    "\n",
    "    for image_path in images:\n",
    "        match = re.search(r\"\\d{14}\", image_path.stem)\n",
    "        if match:\n",
    "            # Extract the first 8 digits (YYYYMMDD) from the match for the date\n",
    "            datetime_str = match.group(0)[:8]\n",
    "            datetime_obj = datetime.strptime(datetime_str, \"%Y%m%d\")\n",
    "            formatted_date = datetime_obj.strftime(\n",
    "                \"%d %b %Y\"\n",
    "            )  # Format the date string as needed\n",
    "        else:\n",
    "            formatted_date = \"Unknown Date\"\n",
    "        # Extract image_id from the file name (assuming format \"_<id>.tif\")\n",
    "        image_id = image_path.stem.split(\"_\")[-1]\n",
    "\n",
    "        # Filter the GeoDataFrame for the current image_id\n",
    "        gdf_filtered = gdf[gdf[\"image_id\"] == int(image_id)]\n",
    "        if not gdf_filtered.empty:\n",
    "            business_name = gdf_filtered[\"USER_Name_of_business\"].iloc[0]\n",
    "            title = f\"{image_id} - {business_name} ({formatted_date})\"\n",
    "        else:\n",
    "            title = f\"{image_id} ({formatted_date})\"\n",
    "        # Existing code for extracting datetime_str, formatted_date, image_id, and title...\n",
    "\n",
    "        with rio.open(image_path) as src:\n",
    "            # Dynamically adjust figure size based on the image dimensions\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "            ax.set_title(title, pad=20)\n",
    "            show(\n",
    "                src, ax=ax, with_bounds=False\n",
    "            )  # with_bounds=False to not alter aspect ratio\n",
    "\n",
    "            # Calculate an approximate scale in meters per degree at the raster's central latitude\n",
    "            central_lat = np.mean([src.bounds.top, src.bounds.bottom])\n",
    "            meters_per_degree = (\n",
    "                111132.92\n",
    "                - 559.82 * np.cos(2 * central_lat * np.pi / 180)\n",
    "                + 1.175 * np.cos(4 * central_lat * np.pi / 180)\n",
    "                - 0.0023 * np.cos(6 * central_lat * np.pi / 180)\n",
    "            )\n",
    "            dx = (\n",
    "                src.res[0] * meters_per_degree\n",
    "            )  # Convert pixel size from degrees to meters\n",
    "\n",
    "            # Add a scale bar\n",
    "            scalebar = ScaleBar(dx, units=\"m\", location=\"lower right\")\n",
    "            ax.add_artist(scalebar)\n",
    "\n",
    "            ax.set_axis_off()\n",
    "\n",
    "            temp_png_path = image_path.with_suffix(\".png\")\n",
    "            plt.savefig(temp_png_path, dpi=300)  # Specify DPI for image quality\n",
    "            plt.close(fig)\n",
    "\n",
    "            image_width_in_points = 8 * 72\n",
    "            image_height_in_points = 8 * 72\n",
    "            x_position = (page_width - image_width_in_points) / 2\n",
    "            y_position = (page_height - image_height_in_points) / 2\n",
    "\n",
    "            # Draw the image centered on the page\n",
    "            c.drawImage(\n",
    "                str(temp_png_path),\n",
    "                x_position,\n",
    "                y_position,\n",
    "                width=image_width_in_points,\n",
    "                height=image_height_in_points,\n",
    "                preserveAspectRatio=True,\n",
    "            )\n",
    "            c.showPage()\n",
    "\n",
    "            temp_png_path.unlink()\n",
    "\n",
    "    c.save()\n",
    "\n",
    "\n",
    "# List of your image paths\n",
    "image_folder = output_folder / \"extracted_images\"\n",
    "images = list(image_folder.glob(\"*.tif\"))\n",
    "\n",
    "# Ensure images list is not longer than 50 items\n",
    "images = images[:50]\n",
    "\n",
    "# Output PDF path\n",
    "pdf_path = output_folder / \"output_images.pdf\"\n",
    "\n",
    "# Create PDF\n",
    "add_images_to_pdf(image_folder, pdf_path, sites_gdf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0be6a230cf1e51d09a2a433a1ab7b0fc195a7ed433ae26bb34d0f4728802d05"
  },
  "kernelspec": {
   "display_name": "Python 3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
